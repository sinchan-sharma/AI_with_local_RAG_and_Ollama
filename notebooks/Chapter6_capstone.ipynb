{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db5eb127",
   "metadata": {},
   "source": [
    "### **Capstone Project: \"Intelligent Document Assistant (IDA) with Local RAG & Observability\"**\n",
    "\n",
    "**Project Goal:** Develop a robust, local-first Intelligent Document Assistant that can answer complex questions, summarize content, and potentially extract specific information from a collection of diverse documents, utilizing LangChain for RAG and Ollama for the LLM, with integrated LangSmith tracing.\n",
    "\n",
    "\n",
    "\n",
    "**1. Document Ingestion Pipeline (Script/Notebook):**\n",
    "\n",
    "Diverse Document Collection: Students assemble a small dataset of 5-10 varied documents (e.g., PDFs of research papers, text files of articles, an HTML page, a JSON file with structured data).\n",
    "\n",
    "Document Loading: Implement code using different DocumentLoaders to load all documents.\n",
    "\n",
    "Text Splitting Strategy: Implement RecursiveCharacterTextSplitter and justify the chosen chunk size/overlap. Show a brief demo/comparison with CharacterTextSplitter.\n",
    "\n",
    "Embedding Generation: Use at least two embedding models (one API-based, one local via HuggingFace embedding library) to generate embeddings for chunks. Discuss pros/cons.\n",
    "\n",
    "Vector Store Population: Populate a FAISS or ChromaDB instance with the generated embeddings and document chunks.\n",
    "\n",
    "**2. Intelligent Document Assistant (IDA) Application:**\n",
    "\n",
    "Local LLM Setup: Demonstrate successful setup and running of an LLM via Ollama.\n",
    "\n",
    "***Q&A Chain:***\n",
    "\n",
    "Build a LangChain RunnableSequence or RetrievalQA chain.\n",
    "\n",
    "Integrate the selected Ollama LLM and the populated Vector Store (Retriever).\n",
    "\n",
    "Craft effective prompts (e.g., instruction-based, contextualized) for question answering.\n",
    "\n",
    "Demonstrate handling various question types (factual, interpretive).\n",
    "\n",
    "***Summarization Chain:***\n",
    "\n",
    "Build a separate chain to summarize retrieved document chunks relevant to a given query or a specific document.\n",
    "\n",
    "Utilize Output Parsers to ensure the summary is a clean text string.\n",
    "\n",
    "***Simple Information Extraction Chain (Optional/Stretch Goal):***\n",
    "\n",
    "A chain that can extract specific entities (e.g., dates, names, key terms) based on a prompt from the retrieved context.\n",
    "\n",
    "Emphasize the use of structured Output Parsers (e.g., PydanticOutputParser or StructuredOutputParser).\n",
    "\n",
    "**3. Observability & Debugging with LangSmith:**\n",
    "\n",
    "Integrate LangSmith tracing for all main chains.\n",
    "\n",
    "Provide screenshots or a recording of the LangSmith UI showing:\n",
    "\n",
    "    Traces of successful Q&A and summarization requests.\n",
    "\n",
    "    An example of debugging a problematic trace (e.g., poor retrieval, bad prompt response).\n",
    "\n",
    "    Analysis of token usage or latency metrics (if visible).\n",
    "\n",
    "Discuss debugging steps and best practices learned.\n",
    "\n",
    "**Final Deliverables:**\n",
    "\n",
    "Python Scripts/Jupyter Notebooks: Well-documented and runnable code for the entire pipeline and the IDA application.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
